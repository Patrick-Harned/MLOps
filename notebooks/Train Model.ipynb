{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "proj_root = os.path.dirname(os.path.abspath(''))\n",
    "sys.path.insert(0, proj_root)\n",
    "print(proj_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22.1\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import tarfile\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data set \n",
    "data_bunch = datasets.load_breast_cancer()\n",
    "data_bunch.frame = pd.DataFrame(data_bunch.data, columns= data_bunch.feature_names).assign(target=data_bunch.target)\n",
    "feature_cols = data_bunch.feature_names\n",
    "label_col = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split and save data locally\n",
    "split=int(data_bunch.frame.shape[0]*.2)\n",
    "np.random.seed(123)\n",
    "idx = np.random.permutation(data_bunch.frame.index)\n",
    "val_idx , train_idx = idx[:split], idx[split:]\n",
    "\n",
    "filename = os.path.split(data_bunch.filename)[-1]\n",
    "data_dir = '../data'\n",
    "\n",
    "data_bunch.frame.loc[val_idx,:].to_csv(os.path.join(data_dir, 'val_'+filename), index=False)\n",
    "data_bunch.frame.loc[train_idx,:].to_csv(os.path.join(data_dir, 'train_'+filename), index=False)\n",
    "val_filename = 'val_'+filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store Data in CP4D project\n",
    "from app.pipeline import Pipeline as _Pipeline\n",
    "\n",
    "pipeline = _Pipeline()\n",
    "pipeline.set_connection()\n",
    "pipeline.set_project('mlops')\n",
    "asset_details = pipeline.wml_client.get_asset_details()\n",
    "if val_filename not in [i['name'] for i in asset_details]:\n",
    "    pipeline.wml_client.data_assets.create(val_filename, val_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete data asset\n",
    "# asset_details = pipeline.wml_client.get_asset_details()\n",
    "# for record in asset_details:\n",
    "#     if record['name'] == filename:\n",
    "#         pipeline.wml_client.delete(record['asset_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, target):\n",
    "    clf = svm.SVC(gamma=0.001, C=100., probability=True)\n",
    "    clf.fit(data, target)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_model(clf, _dir, name):\n",
    "    pklpath = os.path.join(_dir, name + '.pkl')\n",
    "    with open(pklpath, \"wb\") as f:\n",
    "        pickle.dump(clf, f)\n",
    "    \n",
    "    tar_filepath = os.path.splitext(pklpath)[0] + '.tar.gz'\n",
    "    with tarfile.open(tar_filepath, 'w:gz') as tar:\n",
    "        # specify arcname= as file w/o path so \n",
    "        # that file is extracted into same folder \n",
    "        # that extraction is triggered in\n",
    "        pklname = os.path.split(pklpath)[-1]\n",
    "        tar.add(pklpath, arcname=pklname)\n",
    "    os.remove(pklpath)\n",
    "    return tar_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_serialized_model(tarpath):\n",
    "    with tarfile.open(tarpath, 'r:gz') as tar:\n",
    "        _dir, tarname = os.path.split(tarpath)\n",
    "        pklname = tarname.rstrip('.tar.gz') + '.pkl'\n",
    "        tar.extract(pklname, path=_dir)\n",
    "    pklpath = os.path.join(_dir, pklname)\n",
    "    with open(pklpath, 'rb') as f:\n",
    "        pipeline = pickle.load(f)\n",
    "    os.remove(pklpath)\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "train_data = pd.read_csv('../data/train_'+filename)\n",
    "val_data = pd.read_csv('../data/val_'+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93        40\n",
      "           1       0.96      0.96      0.96        73\n",
      "\n",
      "    accuracy                           0.95       113\n",
      "   macro avg       0.94      0.94      0.94       113\n",
      "weighted avg       0.95      0.95      0.95       113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and score model\n",
    "clf = train(train_data[feature_cols], train_data[label_col])\n",
    "pipeline = Pipeline([('svc', clf)])\n",
    "\n",
    "preds = pipeline.predict(val_data.drop(label_col, axis=1))\n",
    "print(classification_report(val_data[label_col], preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../models/svm.tar.gz'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tarpath = serialize_model(pipeline, '../models', 'svm')\n",
    "tarpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93        40\n",
      "           1       0.96      0.96      0.96        73\n",
      "\n",
      "    accuracy                           0.95       113\n",
      "   macro avg       0.94      0.94      0.94       113\n",
      "weighted avg       0.95      0.95      0.95       113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#load and predict from saved model\n",
    "pipeline = load_serialized_model(tarpath)\n",
    "\n",
    "preds = pipeline.predict(val_data.drop(label_col, axis=1))\n",
    "print(classification_report(val_data[label_col], preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lowes",
   "language": "python",
   "name": "lowes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
